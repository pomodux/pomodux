# Retrospective Analysis Rule

## Purpose
This rule is triggered after the completion or failure of a release to perform a comprehensive retrospective analysis. The goal is to capture lessons learned, audit documentation and cursor rules, and suggest improvements for future releases.

## Trigger Conditions
- Release completion (successful or failed)
- Release cancellation or significant scope changes
- Major issues discovered post-release
- User feedback indicating significant problems

## Retrospective Process

### 1. Brainstorm Lessons Learned

**Objective**: Identify all potential lessons learned from the release experience

**Process**:
- Review the entire release lifecycle from planning to completion
- Consider technical, process, communication, and user experience aspects
- Focus on both successes and failures
- Identify patterns that could be improved

**Key Areas to Examine**:
- **Planning Phase**: Were requirements clear? Was the scope appropriate?
- **Development Phase**: Did TDD work effectively? Were there technical challenges?
- **Testing Phase**: Was user testing comprehensive? Were issues caught early?
- **Release Phase**: Were all gates properly executed? Was documentation complete?

**Questions to Consider**:
- What went well during this release?
- What could have gone better?
- What surprised us (positively or negatively)?
- What would we do differently next time?
- Were there any missed opportunities or risks?

### 2. Capture User Lessons Learned

**Objective**: Gather specific feedback and lessons from the user's perspective

**Process**:
- Ask the user to share their experience with the release process
- Focus on their direct observations and insights
- Capture both positive feedback and areas for improvement
- Document specific examples and scenarios

**Key Questions for User**:
- How did the release planning process work for you?
- Were the approval gates helpful or burdensome?
- What aspects of development went smoothly?
- What challenges did you encounter?
- How effective was the user testing phase?
- What would you change about the release process?
- Were there any communication or coordination issues?
- How well did the documentation support the process?

**Documentation Format**:
```markdown
## User Retrospective Feedback - Release X.Y.Z

### Positive Experiences
- [List specific positive aspects]

### Areas for Improvement
- [List specific areas that need work]

### Process Observations
- [List observations about the release process]

### Technical Insights
- [List technical lessons learned]

### Recommendations
- [List specific recommendations for future releases]
```

### 3. Complete Documentation Audit

**Objective**: Ensure all documentation is current, accurate, and useful

**Audit Scope**:
- Review all files in the `docs/` directory
- Check for consistency and completeness
- Verify links and references
- Assess documentation quality and usefulness

**Documentation Categories to Audit**:

#### 3.1 Release Documentation (`docs/releases/`)
- [ ] Verify all release documents follow naming conventions
- [ ] Check that final release documents supersede planning documents
- [ ] Ensure release status indicators are accurate
- [ ] Verify all gate approvals are properly documented
- [ ] Check that release artifacts and installation instructions are current

#### 3.2 Architecture Decision Records (`docs/adr/`)
- [ ] Review all ADRs for current relevance
- [ ] Check that new architectural decisions are documented
- [ ] Verify ADR status indicators (approved/pending/deprecated)
- [ ] Ensure ADRs include required component information
- [ ] Check for any superseded or outdated decisions

#### 3.3 Process Documentation
- [ ] **Release Management** (`docs/release-management.md`)
  - [ ] Verify gate processes are current
  - [ ] Check approval criteria are appropriate
  - [ ] Ensure documentation standards are followed
- [ ] **Development Setup** (`docs/development-setup.md`)
  - [ ] Verify setup instructions are current
  - [ ] Check tool versions and dependencies
  - [ ] Ensure environment requirements are accurate
- [ ] **Go Standards** (`docs/go-standards.md`)
  - [ ] Review coding standards for relevance
  - [ ] Check that standards align with current practices
  - [ ] Verify testing requirements are appropriate

#### 3.4 Project Documentation
- [ ] **Requirements** (`docs/requirements.md`)
  - [ ] Verify requirements reflect current project state
  - [ ] Check for any new requirements discovered during release
  - [ ] Ensure requirements are testable and measurable
- [ ] **Technical Specifications** (`docs/technical_specifications.md`)
  - [ ] Review technical approach for current relevance
  - [ ] Check that specifications align with implementation
  - [ ] Verify architecture decisions are reflected
- [ ] **Implementation Roadmap** (`docs/implementation-roadmap.md`)
  - [ ] Update roadmap based on release experience
  - [ ] Adjust timelines and priorities as needed
  - [ ] Incorporate lessons learned into future planning

#### 3.5 Current Release and Backlog
- [ ] **Current Release** (`docs/current-release.md`)
  - [ ] Update with actual release outcomes
  - [ ] Document any deviations from plan
  - [ ] Record lessons learned for future reference
- [ ] **Backlog** (`docs/backlog.md`)
  - [ ] Update priorities based on release experience
  - [ ] Add new items discovered during release
  - [ ] Remove or adjust items based on lessons learned

**Documentation Quality Checklist**:
- [ ] All documents are current and accurate
- [ ] Links and references work correctly
- [ ] Information is consistent across documents
- [ ] Documentation follows established standards
- [ ] No outdated or superseded information remains
- [ ] All required sections are present and complete

### 4. Complete Cursor Rules Audit

**Objective**: Ensure cursor rules are current, effective, and aligned with project needs

**Audit Scope**:
- Review all cursor rules for relevance and effectiveness
- Check for conflicts or redundancies
- Verify rules support current development practices
- Assess rule clarity and usability

**Rules to Audit**:

#### 4.1 Architecture Guidelines
- [ ] Review ADR philosophy and requirements
- [ ] Check component selection criteria
- [ ] Verify decision documentation guidelines
- [ ] Ensure process workflows are current

#### 4.2 Development Standards
- [ ] Review coding style preferences
- [ ] Check file organization patterns
- [ ] Verify documentation patterns
- [ ] Ensure error handling standards are appropriate

#### 4.3 Workflow Integration
- [ ] Check development process alignment
- [ ] Verify quality assurance requirements
- [ ] Review context awareness guidelines
- [ ] Ensure communication standards are effective

**Rule Quality Checklist**:
- [ ] Rules are clear and unambiguous
- [ ] Rules support current project goals
- [ ] No conflicting or redundant rules
- [ ] Rules are practical and implementable
- [ ] Rules align with documented processes
- [ ] Rules support quality and consistency

### 5. Suggest Updates and Improvements

**Objective**: Propose specific changes based on retrospective findings

**Update Categories**:

#### 5.1 Process Improvements
- **Release Management**: Suggest changes to gate processes, approval criteria, or documentation requirements
- **Development Workflow**: Propose improvements to TDD process, testing approaches, or quality assurance
- **Communication**: Recommend changes to stakeholder communication or status reporting

#### 5.2 Documentation Updates
- **New Documentation**: Identify gaps that need new documentation
- **Updated Documentation**: Suggest specific updates to existing documents
- **Documentation Standards**: Propose improvements to documentation processes or templates

#### 5.3 Cursor Rules Updates
- **New Rules**: Propose new rules based on lessons learned
- **Rule Modifications**: Suggest changes to existing rules for clarity or effectiveness
- **Rule Removal**: Identify obsolete or ineffective rules that should be removed

#### 5.4 Technical Improvements
- **Architecture Changes**: Suggest architectural improvements based on release experience
- **Tooling Updates**: Propose changes to development tools or processes
- **Quality Enhancements**: Recommend improvements to testing, code quality, or performance

**Update Proposal Format**:
```markdown
## Proposed Updates - Release X.Y.Z Retrospective

### Process Improvements
#### [Specific Process Area]
- **Current State**: [Description of current process]
- **Issue**: [Problem or opportunity identified]
- **Proposed Change**: [Specific change to implement]
- **Rationale**: [Why this change is beneficial]
- **Impact**: [Expected impact on future releases]

### Documentation Updates
#### [Document Name]
- **Current State**: [Description of current documentation]
- **Issue**: [Problem or gap identified]
- **Proposed Change**: [Specific update to implement]
- **Rationale**: [Why this update is needed]
- **Implementation**: [How to implement the change]

### Cursor Rules Updates
#### [Rule Category]
- **Current Rule**: [Description of current rule]
- **Issue**: [Problem or opportunity identified]
- **Proposed Change**: [Specific change to implement]
- **Rationale**: [Why this change is beneficial]
- **Implementation**: [How to implement the change]
```

## Retrospective Output

**Required Deliverables**:
1. **Lessons Learned Summary**: Comprehensive list of lessons learned from the release
2. **User Feedback Document**: Captured user insights and recommendations
3. **Documentation Audit Report**: Detailed findings from documentation review
4. **Cursor Rules Audit Report**: Assessment of current rules and effectiveness
5. **Update Proposals**: Specific recommendations for improvements

**Output Format**:
- Create a new file: `docs/retrospectives/retrospective-release-X.Y.Z.md`
- Include all findings and recommendations
- Link to relevant documentation and rules
- Provide clear action items for implementation

**Follow-up Actions**:
- Schedule review of proposed updates
- Prioritize changes based on impact and effort
- Implement approved changes before next release
- Update documentation and rules as needed
- Communicate changes to stakeholders

## Integration with Release Management

**Post-Retrospective Integration**:
- Update release management documentation with lessons learned
- Incorporate process improvements into future release planning
- Update approval gates based on retrospective findings
- Modify documentation standards as needed
- Adjust cursor rules to support improved processes

**Continuous Improvement**:
- Use retrospective findings to inform next release planning
- Track implementation of proposed changes
- Measure effectiveness of improvements in subsequent releases
- Maintain retrospective findings for historical reference

This retrospective process ensures that each release contributes to continuous improvement of the development process, documentation quality, and cursor rule effectiveness. 